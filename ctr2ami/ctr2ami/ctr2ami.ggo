package punk

import (
	"archive/tar"
	"bufio"
	"context"
	"crypto/rand"
	"crypto/sha256"
	"encoding/json"
	"errors"
	"fmt"
	"io"
	"net"
	"os"
	"os/exec"
	"os/signal"
	"path"
	"path/filepath"
	"slices"
	"strings"
	"syscall"
	"time"

	zfs "github.com/bicomsystems/go-libzfs"
	"github.com/firecracker-microvm/firecracker-go-sdk"
	"github.com/firecracker-microvm/firecracker-go-sdk/client/models"
	"github.com/fsnotify/fsnotify"
	"github.com/google/go-containerregistry/pkg/name"
	v1 "github.com/google/go-containerregistry/pkg/v1"
	"github.com/google/go-containerregistry/pkg/v1/mutate"
	"github.com/google/go-containerregistry/pkg/v1/remote"
	"github.com/hashicorp/go-multierror"
	"github.com/sirupsen/logrus"
	"golang.org/x/sys/unix"
)

const (
	cid                   = 9999
	firecrackerExecutable = "firecracker"
	fsDefaultSize         = "1G"
	fsTypeExt4            = "ext4"
	imagesRoot            = "images"
	mkfs                  = "mkfs"
	propImage             = "co.cloudboss:user-image"
	snapshotFinal         = "@final"
	snapshotEmpty         = "@empty"
	stdPermDir            = 0755
	volumesRoot           = "volumes"
	zfsCmd                = "zfs"
	zfsCmdTimeout         = 30 * time.Second
	zvolRoot              = "/dev/zvol"

	memSizeMiB int64 = 1024
	nCPU       int64 = 2
)

var (
	errInvalidEnvironmentImage = errors.New("image environment variables are not valid")
	errInvalidEnvironmentUser  = errors.New("user environment variables are not valid")
	errNotFound                = errors.New("image not found")
)

type Fuse struct {
	Cmd        []string `json:"cmd,omitempty"`
	Entrypoint []string `json:"entrypoint,omitempty"`
	Env        []string `json:"env,omitempty"`
	WorkingDir string   `json:"working_dir,omitempty"`
}

type LighterOpt func(l *lighter)

func WithCacheDir(cacheDir string) LighterOpt {
	return func(l *lighter) {
		l.CacheDir = cacheDir
	}
}

func WithCmd(cmd []string) LighterOpt {
	return func(l *lighter) {
		l.Cmd = cmd
	}
}

func WithEntrypoint(entrypoint []string) LighterOpt {
	return func(l *lighter) {
		l.Entrypoint = entrypoint
	}
}

func WithEnv(env []string) LighterOpt {
	return func(l *lighter) {
		l.Env = env
	}
}

func WithExposedPorts(exposedPorts map[string]struct{}) LighterOpt {
	return func(l *lighter) {
		l.ExposedPorts = exposedPorts
	}
}

func WithHostname(hostname string) LighterOpt {
	return func(l *lighter) {
		l.Hostname = hostname
	}
}

func WithImage(image string) LighterOpt {
	return func(l *lighter) {
		l.Image = image
	}
}

func WithInitrdPath(initrdPath string) LighterOpt {
	return func(l *lighter) {
		l.InitrdPath = initrdPath
	}
}

func WithKernelPath(kernelPath string) LighterOpt {
	return func(l *lighter) {
		l.KernelPath = kernelPath
	}
}

func WithSandboxDir(sandboxDir string) LighterOpt {
	return func(l *lighter) {
		l.SandboxDir = sandboxDir
	}
}

func WithUser(user string) LighterOpt {
	return func(l *lighter) {
		l.User = user
	}
}

func WithVolumes(volumes map[string]struct{}) LighterOpt {
	return func(l *lighter) {
		l.Volumes = volumes
	}
}

func WithWorkingDir(workingDir string) LighterOpt {
	return func(l *lighter) {
		l.WorkingDir = workingDir
	}
}

func WithZFSRoot(zfsRoot string) LighterOpt {
	return func(l *lighter) {
		l.ZFSRoot = zfsRoot
	}
}

func NewLighter(opts ...LighterOpt) (*lighter, error) {
	l := &lighter{}
	for _, opt := range opts {
		opt(l)
	}
	err := l.validateOpts()
	if err != nil {
		return nil, err
	}
	l.tmpDir, err = os.MkdirTemp(l.SandboxDir, "")
	if err != nil {
		return nil, err
	}
	fmt.Printf("Temp dir: %s\n", l.tmpDir)
	return l, nil
}

type lighter struct {
	CacheDir     string              `json:"cache_dir,omitempty"`
	Cmd          []string            `json:"cmd,omitempty"`
	Entrypoint   []string            `json:"entrypoint,omitempty"`
	Env          []string            `json:"env,omitempty"`
	ExposedPorts map[string]struct{} `json:"exposed_ports,omitempty"`
	Hostname     string              `json:"hostname,omitempty"`
	Image        string              `json:"image,omitempty"`
	InitrdPath   string              `json:"initrd_path,omitempty"`
	KernelPath   string              `json:"kernel_path,omitempty"`
	SandboxDir   string              `json:"sandbox_dir,omitempty"`
	User         string              `json:"user,omitempty"`
	Volumes      map[string]struct{} `json:"volumes,omitempty"`
	WorkingDir   string              `json:"working_dir,omitempty"`
	ZFSRoot      string              `json:"zfs_root,omitempty"`

	finalConfig  v1.Config
	listener     net.Listener
	listenerStop bool
	tmpDir       string
}

func (l *lighter) Light() error {

	vmID, err := randomSHA256()
	if err != nil {
		return err
	}
	fmt.Printf("vm ID: %s\n", vmID)

	defer l.cleanup(vmID)

	err = l.ensureExtractBinaries()
	if err != nil {
		return fmt.Errorf("failed to ensure embedded firecracker: %w", err)
	}

	ref, err := name.ParseReference(l.Image)
	if err != nil {
		return err
	}

	// TODO: check for locally cached tarball of image before remote.

	image, err := remote.Image(ref)
	if err != nil {
		return err
	}
	cfgFile, err := image.ConfigFile()
	if err != nil {
		return err
	}
	err = l.mergeConfigs(cfgFile.Config)
	fmt.Printf("config before: %+v\n", cfgFile.Config)

	// TODO: cache the tarball of the image here.

	imageSnapshot, err := l.ensureVMImage(image, ref.String())
	if err != nil {
		return err
	}
	// defer imageSnapshot.Close()

	err = l.cloneSnapshot(imageSnapshot, vmID)
	// err = snapshotClone(path.Join(l.ZFSRoot, imagesRoot, imageSnapshot+snapshotFinal),
	// 	zvolRoot, l.ZFSRoot, path.Join(l.ZFSRoot, volumesRoot, vmID))
	if err != nil {
		return err
	}

	err = l.startListener()
	if err != nil {
		return err
	}

	return l.startVM(vmID)
}

func (l *lighter) cloneSnapshot(snapshot *zfs.Dataset, vmID string) error {
	// fmt.Printf("snapshot properties: %+v\n", snapshot.Properties)

	zfsPath := path.Join(l.ZFSRoot, volumesRoot, vmID)
	fmt.Printf("going to clone %+v to %s\n", snapshot, zfsPath)

	props := map[zfs.Prop]zfs.Property{
		zfs.DatasetPropVolsize: {Value: snapshot.Properties[zfs.DatasetPropVolsize].Value},
		// zfs.DatasetPropVolsize: {Value: fsDefaultSize},
	}

	// return snapshotClone(snapshotName, zvolRoot, l.ZFSRoot, zfsPath)
	rootVolume, err := snapshot.Clone(zfsPath, props)
	if err != nil {
		return err
	}
	rootVolume.Close()
	// fmt.Println("did the clone")
	// closeVolume := func() {
	// 	rootVolume.Close()
	// }
	return waitForPath(path.Join(zvolRoot, zfsPath))
}

func (l *lighter) startVM(vmID string) (err error) {
	// rootDeviceLink := path.Join(zvolRoot, l.ZFSRoot, volumesRoot, vmID)
	// rootDevice, err := os.Readlink(rootDeviceLink)
	// if err != nil {
	// 	return err
	// }
	fcConfig := l.firecrackerConfig(vmID)

	fmt.Printf("fcConfig path 0: %s\n", *fcConfig.Drives[0].PathOnHost)
	fmt.Printf("fcConfig path 1: %s\n", *fcConfig.Drives[1].PathOnHost)

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	logger := logrus.New()
	opts := []firecracker.Opt{
		firecracker.WithLogger(logrus.NewEntry(logger)),
		firecracker.WithProcessRunner(firecracker.VMCommandBuilder{}.
			WithBin(path.Join(l.CacheDir, files.FirecrackerExecutable)).
			WithSocketPath(fcConfig.SocketPath).
			WithStderr(os.Stderr).
			WithStdin(os.Stdin).
			WithStdout(os.Stdout).
			Build(ctx)),
	}
	machine, err := firecracker.NewMachine(ctx, *fcConfig, opts...)
	if err != nil {
		return fmt.Errorf("unable to create new machine: %w", err)
	}

	err = machine.Start(ctx)
	if err != nil {
		return fmt.Errorf("unable to start machine: %w", err)
	}
	defer func() {
		stopErr := machine.StopVMM()
		if stopErr != nil && err != nil {
			err = stopErr
		}
	}()

	installSignalHandlers(ctx, machine, logger)
	err = machine.Wait(ctx)
	return err
}

func (l *lighter) ensureExtractBinaries() (err error) {
	err = os.MkdirAll(l.CacheDir, 0755)
	if err != nil {
		return err
	}
	defer func() {
		if err != nil {
			// Best effort cleanup in case of an error.
			os.RemoveAll(l.CacheDir)
		}
	}()

	binaries := []struct {
		name      string
		sha256sum string
	}{
		{
			name:      files.FirecrackerExecutable,
			sha256sum: files.FirecrackerSHA256Sum,
		},
		{
			name:      files.JailerExecutable,
			sha256sum: files.JailerSHA256Sum,
		},
	}
	for _, binary := range binaries {
		fullPath := filepath.Join(l.CacheDir, binary.name)

		if _, err := os.Stat(fullPath); !errors.Is(err, os.ErrNotExist) {
			contents, err := os.ReadFile(fullPath)
			if err != nil {
				return err
			}
			sha := sha256.New()
			_, err = sha.Write(contents)
			if err != nil {
				return err
			}
			if fmt.Sprintf("%x", sha.Sum(nil)) == binary.sha256sum {
				continue
			}
		}

		contents, err := files.Firecracker.ReadFile(binary.name)
		if err != nil {
			return fmt.Errorf("unable to read embedded %s binary: %w",
				binary.name, err)
		}
		err = os.WriteFile(fullPath, contents, 0755)
		if err != nil {
			return err
		}
	}

	return nil
}

func (l *lighter) ensureFormattedZVol(name string) (*zfs.Dataset, error) {
	zfsPath := path.Join(l.ZFSRoot, imagesRoot, name)

	fmt.Printf("here we go! %s\n", zfsPath)

	// imageExists, err := l.imageExists(name)
	// if err != nil {
	// 	fmt.Printf("we got here: %s\n", err)
	// 	return nil, err
	// }
	// fmt.Printf("image exists: %t\n", imageExists)
	// if !imageExists {
	// 	err = l.imageCreate(name)
	// 	if err != nil {
	// 		return nil, err
	// 	}
	// }

	dataset, err := zfs.DatasetOpen(zfsPath)
	if err != nil {
		fmt.Printf("couldn't find the dataset, trying to create it: %s %T\n", err, err)
		// Dataset "probably" doesn't exist, so try to create it.
		dataset, err = createZVol(zfsPath, fsDefaultSize)
		if err != nil {
			return nil, err
		}
	}

	// // If the "empty" snapshot exists, the volume was formatted.
	// emptyImageExists, err := l.emptyImageExists(name)
	// if err != nil {
	// 	return nil, err
	// }
	// if emptyImageExists {
	// 	return nil, nil
	// }

	// If the "empty" snapshot exists, the volume was formatted.
	if ok, _ := dataset.FindSnapshotName(snapshotEmpty); ok {
		fmt.Println("found the snapshot, returning the dataset")
		return &dataset, nil
	}

	err = makeFilesystem(path.Join(l.ZFSRoot, imagesRoot, name), fsTypeExt4)
	if err != nil {
		return nil, fmt.Errorf("failed to make filesystem: %w", err)
	}

	// // Take the empty snapshot.
	// err = l.imageSnapshotCreate(name, snapshotEmpty)
	// if err != nil {
	// 	return nil, err
	// }

	fmt.Println("taking the empty snapshot for the image")
	_, err = zfs.DatasetSnapshot(zfsPath+snapshotEmpty, false, nil)
	if err != nil {
		return nil, fmt.Errorf("unable to take snapshot: %w", err)
	}
	return &dataset, nil
}

func (l *lighter) ensureVMImage(image v1.Image, ref string) (snapshot *zfs.Dataset, err error) {
	// dataset := &zfs.Dataset{}

	defer func() {
		if snapshot != nil && err != nil {
			snapshot.Close()
		}
	}()

	var (
		dataset       *zfs.Dataset
		finalSnapshot zfs.Dataset
		imageReader   io.ReadCloser
		sha           v1.Hash
		snapshotPath  string
		unmount       func() error
		zfsPath       string
	)

	sha, err = image.Digest()
	if err != nil {
		return nil, fmt.Errorf("failed to get image digest: %w", err)
	}

	dataset, err = l.ensureFormattedZVol(sha.Hex)
	if err != nil {
		return nil, fmt.Errorf("failed to ensure formatted zvol: %w", err)
	}
	defer dataset.Close()

	// finalImageExists, err := l.finalSnapshotExists(sha.Hex)
	// if err != nil {
	// 	return "", fmt.Errorf("failed to get final image snapshot: %w", err)
	// }
	// if finalImageExists {
	// 	return sha.Hex, nil
	// }

	// If the "final" snapshot exists, the volume is ready.
	snapshot, err = zfsGetSnapshot(dataset, snapshotFinal)
	if err != nil || snapshot != nil {
		return snapshot, err
	}

	zfsPath = path.Join(l.ZFSRoot, imagesRoot, sha.Hex)

	fmt.Println("going to mount the zvol")
	unmount, err = mountZVol(zfsPath, sha.Hex)
	if err != nil {
		return nil, fmt.Errorf("failed to mount zvol: %w", err)
	}

	imageReader = mutate.Extract(image)
	defer imageReader.Close()

	err = untar(imageReader, sha.Hex, stdPermDir)
	if err != nil {
		err = fmt.Errorf("failed to extract archive onto zvol: %w", err)
		goto out
	}
	// defer func() {
	// 	if err != nil {
	// 		os.RemoveAll(sha.Hex)
	// 	}
	// }()

	err = setUserProperty(zfsPath, propImage, ref)
	if err != nil {
		err = fmt.Errorf("failed to set user property %s on %s: %w",
			propImage, ref, err)
		goto out
	}

	err = unmount()
	if err != nil {
		return nil, fmt.Errorf("failed to unmount %s: %w", sha.Hex, err)
	}
	dataset.Close()

	// // Take the final snapshot.
	// err = l.imageSnapshotCreate(sha.Hex, snapshotFinal)
	// if err != nil {
	// 	return nil, fmt.Errorf("unable to take final snapshot: %w", err)
	// }

	snapshotPath = path.Join(l.ZFSRoot, imagesRoot, sha.Hex) + snapshotFinal
	fmt.Printf("taking the final snapshot: %s\n", snapshotPath)
	finalSnapshot, err = zfs.DatasetSnapshot(snapshotPath, true, nil)
	if err != nil {
		err = fmt.Errorf("failed to take snapshot %s: %w", snapshotPath, err)
		goto out
	}
	snapshot = &finalSnapshot

out:
	err = unmount()

	return snapshot, err
}

func (l *lighter) validateOpts() error {
	var err error = nil
	if len(l.SandboxDir) == 0 {
		e := errors.New("SandboxDir is required")
		err = multierror.Append(err, e)
	}
	return err
}

func (l *lighter) cleanup(vmID string) (err error) {
	ec := make(chan error, 2)

	ec <- os.RemoveAll(l.tmpDir)

	if l.listener != nil {
		l.listenerStop = true
		ec <- l.listener.Close()
	}

	close(ec)

	for e := range ec {
		if e != nil {
			err = multierror.Append(err, e)
		}
	}
	return err
}

// mergeConfigs merges its own configuration with the image configuration.
func (l *lighter) mergeConfigs(image v1.Config) error {
	config := v1.Config{
		Cmd:          image.Cmd,
		Entrypoint:   image.Entrypoint,
		Env:          image.Env,
		ExposedPorts: image.ExposedPorts,
		Hostname:     image.Hostname,
		Volumes:      image.Volumes,
		WorkingDir:   image.WorkingDir,
	}
	if len(l.Cmd) > 0 {
		config.Cmd = l.Cmd
	}
	if len(l.Entrypoint) > 0 {
		for _, item := range l.Entrypoint {
			fmt.Printf("entrypoint item: --%s--\n", item)
		}
		config.Entrypoint = l.Entrypoint
	}
	if len(l.Env) > 0 {
		env, err := mergeEnv(config.Env, l.Env)
		if err != nil {
			return err
		}
		config.Env = env
	}
	if len(l.ExposedPorts) > 0 {
		fmt.Printf("exposed ports: %+v\n", l.ExposedPorts)
		config.ExposedPorts = l.ExposedPorts
	}
	if len(l.Hostname) > 0 {
		fmt.Printf("hostname: %+v\n", l.Hostname)
		config.Hostname = l.Hostname
	}

	// Skip merging in Image, the image is already its own source of truth.

	if len(l.Volumes) > 0 {
		fmt.Printf("volumes: %+v\n", l.Volumes)
		config.Volumes = l.Volumes
	}
	if len(l.WorkingDir) > 0 {
		fmt.Printf("working dir: %+v\n", l.WorkingDir)
		config.WorkingDir = l.WorkingDir
	}
	fmt.Printf("final config: %+v\n", config)
	l.finalConfig = config
	return nil
}

func (l *lighter) firecrackerConfig(vmID string) *firecracker.Config {
	return &firecracker.Config{
		SocketPath:      path.Join(l.tmpDir, "control"),
		LogFifo:         path.Join(l.tmpDir, "log"),
		LogLevel:        "Debug",
		MetricsFifo:     path.Join(l.tmpDir, "metrics"),
		FifoLogWriter:   nil,
		KernelImagePath: l.KernelPath,
		KernelArgs:      "console=ttyS0 panic=1 pci=off reboot=k",
		InitrdPath:      l.InitrdPath,
		Drives: []models.Drive{
			{
				CacheType:    p("Unsafe"),
				DriveID:      p("rootfs"),
				PathOnHost:   p(path.Join(zvolRoot, l.ZFSRoot, volumesRoot, vmID)),
				IoEngine:     p("Sync"),
				IsReadOnly:   p(false),
				IsRootDevice: p(false),
			},
			{
				CacheType:    p("Unsafe"),
				DriveID:      p("modules"),
				PathOnHost:   p(path.Join(zvolRoot, "punk/modules")),
				IoEngine:     p("Sync"),
				IsReadOnly:   p(false),
				IsRootDevice: p(false),
			},
		},
		NetworkInterfaces: firecracker.NetworkInterfaces{},
		VsockDevices: []firecracker.VsockDevice{
			{
				Path: path.Join(l.tmpDir, "vsock"),
				CID:  cid,
			},
		},
		MachineCfg: models.MachineConfiguration{
			VcpuCount: p(nCPU),
			// CPUTemplate: models.CPUTemplate(opts.FcCPUTemplate),
			Smt:        p(false),
			MemSizeMib: p(memSizeMiB),
		},
		VMID: vmID,
	}
}

func (l *lighter) imageExists(name string) (bool, error) {
	return datasetExists(path.Join(l.ZFSRoot, imagesRoot, name))
}

func (l *lighter) emptyImageExists(name string) (bool, error) {
	return datasetExists(path.Join(l.ZFSRoot, imagesRoot, name+snapshotEmpty))
}

func (l *lighter) finalSnapshotExists(name string) (bool, error) {
	return datasetExists(path.Join(l.ZFSRoot, imagesRoot, name+snapshotFinal))
}

func (l *lighter) imageCreate(name string) error {
	return zvolCreate(path.Join(l.ZFSRoot, imagesRoot, name), fsDefaultSize)
}

func (l *lighter) imageSnapshotCreate(imageName, snapshotName string) error {
	return snapshotCreate(path.Join(l.ZFSRoot, imagesRoot, imageName+snapshotName))
}

func (l *lighter) handle() {
	fmt.Println("going to accept()")

	cx, err := l.listener.Accept()
	if err != nil {
		return
	}
	defer cx.Close()

	fmt.Printf("received a connection: %+v\n", cx)

	fuse := &Fuse{
		Cmd:        l.finalConfig.Cmd,
		Entrypoint: l.finalConfig.Entrypoint,
		Env:        l.finalConfig.Env,
		WorkingDir: l.finalConfig.WorkingDir,
	}
	fmt.Printf("what's the fuse? %+v\n", fuse)

	err = json.NewEncoder(cx).Encode(fuse)
	if err != nil {
		fmt.Fprintf(os.Stderr, "error writing to vsock: %s\n", err)
	}
}

func (l *lighter) startListener() error {
	listener, err := net.Listen("unix", path.Join(l.tmpDir, fmt.Sprintf("vsock_%d", cid)))
	if err != nil {
		return err
	}
	l.listener = listener
	go func() {
		for {
			l.handle()
			if l.listenerStop {
				return
			}
		}
	}()
	return nil
}

func copyFile(src io.Reader, dest string, perm os.FileMode) error {
	f, err := os.OpenFile(dest, os.O_CREATE|os.O_WRONLY, perm)
	if err != nil {
		return err
	}
	defer f.Close()

	_, err = io.Copy(f, src)
	return err
}

type errExtract struct {
	fileType rune
}

func (e errExtract) Error() string {
	what := ""
	switch e.fileType {
	case tar.TypeBlock:
		what = "block device"
	case tar.TypeChar:
		what = "character device"
	case tar.TypeDir:
		what = "directory"
	case tar.TypeFifo:
		what = "fifo"
	case tar.TypeLink:
		what = "hard link"
	case tar.TypeReg:
		what = "file"
	case tar.TypeSymlink:
		what = "symbolic link"
	default:
		return "unknown file type while extracting archive"
	}
	format := "unable to create %s while extracting archive"
	return fmt.Sprintf(format, what)
}

func newErrExtract(fileType rune, wrap error) error {
	err := errExtract{fileType: fileType}
	return fmt.Errorf("%w: %w", err, wrap)
}

func untar(reader io.Reader, destDir string, perm os.FileMode) error {
	oldMask := syscall.Umask(0)
	defer func() {
		syscall.Umask(oldMask)
	}()

	err := os.MkdirAll(destDir, perm)
	if err != nil {
		return err
	}

	timestamps := map[string]int64{}

	treader := tar.NewReader(reader)

	for {
		hdr, err := treader.Next()
		if errors.Is(err, io.EOF) {
			break
		}
		if err != nil {
			return err
		}

		fi := hdr.FileInfo()
		dest := filepath.Join(destDir, hdr.Name)
		timestamps[dest] = hdr.ModTime.Unix()

		switch hdr.Typeflag {
		case tar.TypeBlock:
			dev := int(unix.Mkdev(uint32(hdr.Devmajor), uint32(hdr.Devminor)))
			err = syscall.Mknod(dest, syscall.S_IFBLK, dev)
			if err != nil {
				return newErrExtract(tar.TypeBlock, err)
			}
		case tar.TypeChar:
			dev := int(unix.Mkdev(uint32(hdr.Devmajor), uint32(hdr.Devminor)))
			err = syscall.Mknod(dest, syscall.S_IFCHR, dev)
			if err != nil {
				return newErrExtract(tar.TypeChar, err)
			}
		case tar.TypeDir:
			err := os.Mkdir(dest, fi.Mode())
			if err != nil {
				return newErrExtract(tar.TypeDir, err)
			}
		case tar.TypeFifo:
			err = syscall.Mkfifo(dest, uint32(hdr.Mode))
			if err != nil {
				return newErrExtract(tar.TypeFifo, err)
			}
		case tar.TypeLink:
			err := os.Link(filepath.Join(destDir, hdr.Linkname), dest)
			if err != nil {
				return newErrExtract(tar.TypeLink, err)
			}
		case tar.TypeReg:
			err = copyFile(treader, dest, fi.Mode())
			if err != nil {
				return newErrExtract(tar.TypeReg, err)
			}
		case tar.TypeSymlink:
			err := os.Symlink(hdr.Linkname, dest)
			if err != nil {
				return newErrExtract(tar.TypeSymlink, err)
			}
		}

		err = os.Lchown(dest, hdr.Uid, hdr.Gid)
		if err != nil {
			return err
		}
	}

	// Change timestamps at the end, otherwise creation of
	// entries within directories resets parent timestamps.
	for dest, unixSec := range timestamps {
		tv := unix.Timeval{Sec: unixSec}
		err = unix.Lutimes(dest, []unix.Timeval{tv, tv})
		if err != nil {
			return err
		}
	}

	return nil
}

func p[T any](v T) *T {
	return &v
}

func findDatasetByImage(zfsRoot, imageRef string) (zfs.Dataset, error) {
	nilDataset := zfs.Dataset{}

	images, err := zfs.DatasetOpen(zfsRoot)
	if err != nil {
		return nilDataset, err
	}

	dataset, err := findDatasetsByImage(images.Children, imageRef)
	if err != nil {
		return nilDataset, err
	}

	fmt.Printf("got the dataset: %+v\n", dataset)
	return dataset, nil
}

func findDatasetsByImage(datasets []zfs.Dataset, imageRef string) (zfs.Dataset, error) {
	fmt.Printf("finding datasets: %+v\n", datasets)

	nilDataset := zfs.Dataset{}

	for _, dataset := range datasets {
		prop, err := dataset.GetUserProperty(propImage)
		if err != nil {
			return nilDataset, err
		}
		if prop.Value == imageRef {
			return dataset, nil
		}
		ds, err := findDatasetsByImage(dataset.Children, imageRef)
		if errors.Is(err, errNotFound) {
			continue
		}
		if err != nil {
			return nilDataset, err
		}
		return ds, nil
	}
	return nilDataset, errNotFound
}

// mergeEnv merges the image environment with the environment supplied by the user.
func mergeEnv(image, user []string) ([]string, error) {
	merged := []string{}

	// First override any environment variables from the image.
	for _, item := range image {
		fields := strings.Split(item, "=")
		if len(fields) == 1 && fields[0] == item {
			// This unlikely failure would mean the image was
			// created containing invalid environment variables.
			return nil, errInvalidEnvironmentImage
		}
		i := slices.IndexFunc(user, func(s string) bool {
			prefix := fmt.Sprintf("%s=", fields[0])
			return strings.HasPrefix(s, prefix)
		})
		if i >= 0 {
			merged = append(merged, user[i])
			user = slices.Delete(user, i, i+1)
		} else {
			merged = append(merged, item)
		}
	}

	// Check that the remaining user-supplied variables are valid.
	hasInvalid := slices.ContainsFunc(user, func(s string) bool {
		fields := strings.Split(s, "=")
		return len(fields) == 1 && fields[0] == s
	})
	if hasInvalid {
		return nil, errInvalidEnvironmentUser
	}

	// Append remaining variables.
	return append(merged, user...), nil
}

func remove[E any](slice []E, i int) (result []E, err error) {
	defer func() {
		p := recover()
		if p == nil {
			return
		}
		if e, ok := p.(error); ok {
			if strings.Contains(e.Error(), "slice bounds out of range") {
				result = nil
				err = e
				return
			}
		}
		panic(p)
	}()
	result = make([]E, 0)
	result = append(result, slice[:i]...)
	result = append(result, slice[i+1:]...)
	return result, nil
}

func zfsGetSnapshot(dataset *zfs.Dataset, snapshotName string) (*zfs.Dataset, error) {
	ok, found := dataset.FindSnapshotName(snapshotName)
	if !ok {
		return nil, nil
	}
	pathName, err := found.Path()
	if err != nil {
		return nil, err
	}
	snapshot, err := zfs.DatasetOpen(pathName)
	if err != nil {
		return nil, err
	}
	fmt.Printf("returning %+v\n", snapshot)
	return &snapshot, nil
}

func newZFSCmd(args ...string) *exec.Cmd {
	cmd := exec.Command(zfsCmd, args...)
	fmt.Printf("running command %+v\n", cmd)
	cmd.WaitDelay = zfsCmdTimeout
	return cmd
	// err := cmd.Start()
	// fmt.Printf("started command %+v\n", cmd)
	// if err != nil {
	// 	return fmt.Errorf("failed to run `%s %s`: %w",
	// 		zfsCmd, strings.Join(args, " "), err)
	// }
	// return cmd.Wait()
}

func datasetExists(zfsPath string) (bool, error) {
	cmd := newZFSCmd("get", "-H", ":exists", zfsPath)
	out, err := cmd.CombinedOutput()
	if err != nil {
		fmt.Printf("out: %s\n", string(out))
		if strings.Contains(string(out), "dataset does not exist") {
			return false, nil
		}
		return false, err
	}
	return true, nil
}

func zvolCreate(zfsPath, size string) error {
	cmd := newZFSCmd("create", "-V", size, zfsPath)
	return cmd.Run()
}

func snapshotCreate(zfsPath string) error {
	cmd := newZFSCmd("snapshot", zfsPath)
	return cmd.Run()
}

func snapshotClone(snapshotName, devicePath, zfsPool, zfsPath string) error {
	cmd := newZFSCmd("clone", snapshotName, zfsPath)
	err := cmd.Run()
	if err != nil {
		return err
	}
	return waitForPath(path.Join(devicePath, zfsPath))
}

func waitForPath(watchPath string, timeout ...time.Duration) error {
	duration := 10 * time.Second
	if len(timeout) > 0 {
		duration = timeout[0]
	}

	start := time.Now()

	for time.Since(start) < duration {
		if _, err := os.Stat(watchPath); err == nil {
			return nil
		}
		time.Sleep(10 * time.Millisecond)
	}

	return fmt.Errorf("timeout watching %s\n", watchPath)
}

func waitForPathy(watchPath string, timeout ...time.Duration) error {
	// Quick check first.
	if _, err := os.Stat(watchPath); err == nil {
		return nil
	}

	duration := 10 * time.Second
	if len(timeout) > 0 {
		duration = timeout[0]
	}

	watcher, err := fsnotify.NewWatcher()
	if err != nil {
		return fmt.Errorf("unable to create filesystem watcher: %w", err)
	}

	errChan := make(chan error)
	go func() {
		timer := time.NewTimer(duration)
		for {
			fmt.Println("entering the loop")
			select {
			case <-timer.C:
				errChan <- fmt.Errorf("timeout waiting for %s", watchPath)
				return
			case evt := <-watcher.Events:
				fmt.Printf("event: %+v, name: %s\n", evt, evt.Name)
				if evt.Name == watchPath && evt.Op == fsnotify.Create {
					errChan <- nil
					return
				}
				continue
			case err = <-watcher.Errors:
				fmt.Printf("error watching %s: %s\n", watchPath, err)
				continue
			}
		}
	}()

	parentPath := filepath.Dir(watchPath)
	// Hot loop to add watch to parent directory as it may
	// not exist the first time a volume is created.
	for {
		err = watcher.Add(parentPath)
		if err != nil {
			continue
		}
		break
	}
	defer watcher.Remove(watchPath)

	err = <-errChan

	// Final check in case event was missed.
	if _, err := os.Stat(watchPath); err == nil {
		return nil
	}

	return err
}

func setUserProperty(zfsPath, key, value string) error {
	prop := fmt.Sprintf("%s=%s", key, value)
	cmd := newZFSCmd("set", prop, zfsPath)
	return cmd.Run()
}

func createZVol(zfsPath, size string) (zfs.Dataset, error) {
	dataset := zfs.Dataset{}
	props := map[zfs.Prop]zfs.Property{
		zfs.DatasetPropVolsize: {Value: size},
	}
	dataset, err := zfs.DatasetCreate(zfsPath, zfs.DatasetTypeVolume, props)
	if err != nil {
		return dataset, err
	}
	return dataset, nil
}

func makeFilesystem(datasetPath, fsType string) error {
	// datasetPath, err := dataset.Path()
	// if err != nil {
	// 	return fmt.Errorf("unable to get path from dataset: %w", err)
	// }
	absPath := path.Join(zvolRoot, datasetPath)
	mounted, err := isMountedWait(absPath)
	if err != nil {
		return fmt.Errorf("failed to wait for filesystem to be mounted: %w", err)
	}
	if mounted {
		return errors.New("cannot make filesystem on mounted device")
	}
	cmd := exec.Command(mkfs, "-t", fsTypeExt4, absPath)
	return cmd.Run()
}

func mountZVol(
	datasetPath,
	mountPoint string) (unmount func() error, err error) {
	// defer func() {
	// 	if err != nil {
	// 		os.RemoveAll(mountPoint)
	// 	}
	// }()

	err = os.MkdirAll(mountPoint, 0755)
	if err != nil {
		return nil, err
	}

	// datasetPath, err := dataset.Path()
	// if err != nil {
	// 	return nil, err
	// }
	device := path.Join(zvolRoot, datasetPath)
	err = syscall.Mount(device, mountPoint, fsTypeExt4, 0, "")
	if err != nil {
		return nil, err
	}

	unmount = func() error {
		mounted, err := isMounted(device)
		if err != nil {
			return err
		}
		if mounted {
			err = syscall.Unmount(mountPoint, 0)
			if err != nil {
				return err
			}
			// _, err = isUnmountedWait(device)
			// if err != nil {
			// 	return err
			// }
			return os.Remove(mountPoint)
		}
		return nil
	}
	return unmount, nil
}

func deleteZVol(dataset zfs.Dataset) error {
	defer dataset.Close()

	datasetPath, err := dataset.Path()
	if err != nil {
		return err
	}
	fmt.Println(path.Join(zvolRoot, datasetPath))
	mounted, err := isMounted(path.Join(zvolRoot, datasetPath))
	if mounted {
		unmountErr := dataset.Unmount(0)
		if unmountErr != nil {
			return unmountErr
		}
	}
	return dataset.Destroy(false)
}

func isMounted(device string) (bool, error) {
	absPath := device

	deviceStat, err := os.Lstat(device)
	if err != nil {
		return false, err
	}
	if deviceStat.Mode()&os.ModeSymlink != 0 {
		absPath, err = filepath.EvalSymlinks(device)
		if err != nil {
			return false, err
		}
	}

	file, err := os.Open("/proc/mounts")
	if err != nil {
		return false, err
	}
	defer file.Close()

	scanner := bufio.NewScanner(file)
	for scanner.Scan() {
		line := scanner.Text()
		fields := strings.Fields(line)
		if len(fields) < 1 {
			err = fmt.Errorf("unexpected line in /proc/mounts: %s",
				line)
			return false, err
		}
		if fields[0] == absPath || fields[0] == device {
			return true, nil
		}
	}

	return false, nil
}

func mountWait(
	device string,
	f func() (bool, error),
	timeout ...time.Duration) (bool, error) {

	duration := 10 * time.Second
	if len(timeout) > 0 {
		duration = timeout[0]
	}
	timer := time.NewTimer(duration)

	resultC := make(chan bool)

	go func() {
		for {
			cond, err := f()
			fmt.Printf("cond: %t, err: %+v\n", cond, err)
			if err != nil {
				time.Sleep(100 * time.Millisecond)
				continue
			} else {
				resultC <- cond
			}
		}
	}()

	for {
		select {
		case result := <-resultC:
			return result, nil
		case <-timer.C:
			return false, fmt.Errorf("timeout waiting for mount")
		}

	}
}

func isMountedWait(device string, timeout ...time.Duration) (bool, error) {
	f := func() (bool, error) {
		return isMounted(device)
	}
	fmt.Printf("checking if %s is mounted\n", device)
	return mountWait(device, f, timeout...)
}

func isUnmountedWait(device string, timeout ...time.Duration) (bool, error) {
	f := func() (bool, error) {
		mounted, err := isMounted(device)
		if err != nil {
			return false, err
		}
		return !mounted, nil
	}
	fmt.Printf("checking if %s is unmounted\n", device)
	return mountWait(device, f, timeout...)
}

func randomSHA256() (string, error) {
	b := make([]byte, 8)
	_, err := rand.Read(b)
	if err != nil {
		return "", fmt.Errorf("could not read random bytes: %w", err)
	}
	sha256um := sha256.New()
	_, err = sha256um.Write(b)
	if err != nil {
		return "", fmt.Errorf("could not write sha256 checksum: %w", err)
	}
	return fmt.Sprintf("%x", sha256um.Sum(nil)), nil
}

func installSignalHandlers(
	ctx context.Context,
	m *firecracker.Machine,
	logger *logrus.Logger) {
	go func() {
		// Clear some default handlers installed by the firecracker SDK:
		signal.Reset(os.Interrupt, syscall.SIGTERM, syscall.SIGQUIT)
		c := make(chan os.Signal, 1)
		signal.Notify(c, os.Interrupt, syscall.SIGTERM, syscall.SIGQUIT)

		for {
			switch s := <-c; {
			case s == syscall.SIGTERM || s == os.Interrupt:
				logger.Printf("Caught signal: %s, requesting clean shutdown", s.String())
				if err := m.Shutdown(ctx); err != nil {
					logger.Errorf("An error occurred while shutting down Firecracker VM: %v", err)
				}
			case s == syscall.SIGQUIT:
				logger.Printf("Caught signal: %s, forcing shutdown", s.String())
				if err := m.StopVMM(); err != nil {
					logger.Errorf("An error occurred while stopping Firecracker VMM: %v", err)
				}
			}
		}
	}()
}
